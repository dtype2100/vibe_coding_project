import streamlit as st
import json
import os
import pickle
import numpy as np
from uuid import uuid4
from typing import List, Dict, Optional
from sentence_transformers import SentenceTransformer
import faiss

# DB íŒŒì¼ ê²½ë¡œ: ê¸°ì¡´ ì—…ê·¸ë ˆì´ë“œ ë²„ì „ë„ ì§€ì›
DB_FILE = (
    "vibe_prompts_structured.json"
    if os.path.exists("vibe_prompts_structured.json")
    else "vibe_prompts_structured_upgraded.json"
)

# ë²¡í„° ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ
VECTOR_INDEX_FILE = "prompt_vectors.faiss"
EMBEDDING_CACHE_FILE = "embeddings_cache.pkl"

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

# Load prompts
def load_prompts() -> List[Dict]:
    try:
        with open(DB_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return []

# Save prompts
def save_prompts(prompts: List[Dict]) -> None:
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(prompts, f, indent=2, ensure_ascii=False)

# Extract tags from user input
def extract_tags(text: str) -> Dict[str, List[str]]:
    text_lower = text.lower()
    category_keywords = {
        "í”„ë¡ íŠ¸ì—”ë“œ": ["ui", "í¼", "ë¦¬ì•¡íŠ¸", "react", "tailwind", "ìƒíƒœ", "í”„ë¡ íŠ¸"],
        "ë°±ì—”ë“œ": ["api", "ë¡œê·¸ì¸", "fastapi", "ì„œë²„", "rest", "ì¸ì¦"],
        "AI/LLM": ["gpt", "llm", "ìš”ì•½", "langchain", "llama", "í”„ë¡¬í”„íŠ¸"],
        "ë°ì´í„°ë¶„ì„": ["pandas", "ì‹œê°í™”", "csv", "plotly", "ë¶„ì„", "ë°ì´í„°"],
        "DevOps": ["docker", "ë°°í¬", "ci", "github actions"],
        "ê¸°ì´ˆ": ["í™€ìˆ˜", "ì§ìˆ˜", "ê¸°ì´ˆ", "python", "ì…ë¬¸"]
    }
    matched_categories = []
    matched_keywords = []
    for category, keywords in category_keywords.items():
        for kw in keywords:
            if kw in text_lower:
                matched_categories.append(category)
                matched_keywords.append(kw)
    return {
        "categories": sorted(set(matched_categories)),
        "keywords": sorted(set(matched_keywords))
    }

# Simple keyword-based recommendation
def recommend(tags: Dict[str, List[str]], prompts: List[Dict], top_k: int = 3) -> List[Dict]:
    scored = []
    for prompt in prompts:
        score = 0
        if prompt.get("category") in tags["categories"]:
            score += 2
        score += len(set(tags["keywords"]) & set(prompt.get("keywords", [])))
        if score > 0:
            scored.append((score, prompt))
    scored.sort(reverse=True, key=lambda x: x[0])
    return [item for _, item in scored[:top_k]]

# í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
def get_prompt_text(prompt: Dict) -> str:
    return f"{prompt.get('title', '')} {prompt.get('prompt', '')} {' '.join(prompt.get('keywords', []))}"

# ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ë° ë¡œë“œ
@st.cache_data
def build_vector_index(prompts: List[Dict]):
    model = load_embedding_model()
    
    # ìºì‹œëœ ì„ë² ë”©ì´ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists(EMBEDDING_CACHE_FILE):
        with open(EMBEDDING_CACHE_FILE, 'rb') as f:
            cached_data = pickle.load(f)
            if len(cached_data['prompts']) == len(prompts):
                return cached_data['index'], cached_data['embeddings']
    
    # í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ ìƒì„±
    prompt_texts = [get_prompt_text(prompt) for prompt in prompts]
    
    # ì„ë² ë”© ìƒì„±
    embeddings = model.encode(prompt_texts, convert_to_numpy=True)
    
    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)  # Inner Product (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    
    # ì •ê·œí™” í›„ ì¸ë±ìŠ¤ì— ì¶”ê°€
    faiss.normalize_L2(embeddings)
    index.add(embeddings.astype('float32'))
    
    # ìºì‹œ ì €ì¥
    cache_data = {
        'index': index,
        'embeddings': embeddings,
        'prompts': prompts
    }
    with open(EMBEDDING_CACHE_FILE, 'wb') as f:
        pickle.dump(cache_data, f)
    
    return index, embeddings

# ë²¡í„° ê¸°ë°˜ ì¶”ì²œ
def vector_recommend(user_input: str, prompts: List[Dict], top_k: int = 3) -> List[Dict]:
    if not prompts:
        return []
    
    model = load_embedding_model()
    index, embeddings = build_vector_index(prompts)
    
    # ì‚¬ìš©ì ì…ë ¥ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    query_embedding = model.encode([user_input], convert_to_numpy=True)
    faiss.normalize_L2(query_embedding)
    
    # ìœ ì‚¬ë„ ê²€ìƒ‰
    scores, indices = index.search(query_embedding.astype('float32'), min(top_k, len(prompts)))
    
    # ê²°ê³¼ ë°˜í™˜
    results = []
    for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
        if idx < len(prompts):
            prompt = prompts[idx].copy()
            prompt['similarity_score'] = float(score)
            results.append(prompt)
    
    return results

# í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ (í‚¤ì›Œë“œ + ë²¡í„°)
def hybrid_recommend(user_input: str, prompts: List[Dict], top_k: int = 3) -> List[Dict]:
    # í‚¤ì›Œë“œ ê¸°ë°˜ ê²°ê³¼
    keyword_results = recommend(extract_tags(user_input), prompts, top_k * 2)
    
    # ë²¡í„° ê¸°ë°˜ ê²°ê³¼
    vector_results = vector_recommend(user_input, prompts, top_k * 2)
    
    # ê²°ê³¼ ê²°í•© ë° ì¤‘ë³µ ì œê±°
    combined = {}
    
    # í‚¤ì›Œë“œ ê²°ê³¼ (ê°€ì¤‘ì¹˜ 0.4)
    for i, item in enumerate(keyword_results):
        item_id = item.get('id')
        score = (len(keyword_results) - i) * 0.4
        combined[item_id] = {'item': item, 'score': score}
    
    # ë²¡í„° ê²°ê³¼ (ê°€ì¤‘ì¹˜ 0.6)
    for i, item in enumerate(vector_results):
        item_id = item.get('id')
        vector_score = item.get('similarity_score', 0) * 0.6
        
        if item_id in combined:
            combined[item_id]['score'] += vector_score
        else:
            combined[item_id] = {'item': item, 'score': vector_score}
    
    # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
    sorted_results = sorted(combined.values(), key=lambda x: x['score'], reverse=True)
    
    return [result['item'] for result in sorted_results[:top_k]]

# Streamlit UI ì„¤ì •
st.set_page_config(page_title="Vibe Coding Prompt Recommender", layout="wide")
st.title("ğŸ§  ë°”ì´ë¸Œ ì½”ë”© í”„ë¡¬í”„íŠ¸ ì¶”ì²œ ì‹œìŠ¤í…œ")

tab1, tab2, tab3 = st.tabs(["âœ¨ ì¶”ì²œ ë°›ê¸°", "ğŸ“„ í”„ë¡¬í”„íŠ¸ ëª©ë¡", "â• í”„ë¡¬í”„íŠ¸ ì¶”ê°€"])

# Tab 1: ì¶”ì²œ ë°›ê¸°
with tab1:
    st.markdown("ğŸ’¡ ì˜ˆì‹œ: `react ë¡œê·¸ì¸ í¼`, `fastapi íŒŒì¼ ì—…ë¡œë“œ`, `llama-cpp ìš”ì•½ ì±—ë´‡`, `csv ì‹œê°í™”`")
    with st.expander("ğŸ§  ì…ë ¥ ê°€ì´ë“œ ë³´ê¸°"):
        st.markdown(
            """
        - **í•˜ê³  ì‹¶ì€ ì‘ì—…ì„ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.**
        - ê°€ëŠ¥í•œ í•œ ê¸°ìˆ  ì´ë¦„ì´ë‚˜ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ì„¸ìš” (ì˜ˆ: `fastapi`, `csv`, `jwt`, `react`, `llama` ë“±).
        - ì˜ˆì‹œ ì…ë ¥:
            - `fastapië¡œ ë¡œê·¸ì¸ ê¸°ëŠ¥ ë§Œë“¤ê¸°`
            - `csv íŒŒì¼ì„ ì—…ë¡œë“œí•´ì„œ plotlyë¡œ ì‹œê°í™”`
            - `llama-cppë¡œ ìš”ì•½ ì±—ë´‡ ë§Œë“¤ê¸°`
        """
        )
    recommend_mode = st.radio('ì¶”ì²œ ë°©ì‹ ì„ íƒ', ['í‚¤ì›Œë“œ ê¸°ë°˜', 'ë²¡í„° ê¸°ë°˜', 'í•˜ì´ë¸Œë¦¬ë“œ'])
    user_input = st.text_input("ì›í•˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”", placeholder="ì˜ˆ: fastapië¡œ ë¡œê·¸ì¸ api ë§Œë“¤ê³  ì‹¶ì–´")

    if user_input:
        prompts = load_prompts()
        if recommend_mode == 'í‚¤ì›Œë“œ ê¸°ë°˜':
            results = recommend(extract_tags(user_input), prompts)
        elif recommend_mode == 'ë²¡í„° ê¸°ë°˜':
            results = vector_recommend(user_input, prompts)
        else:  # í•˜ì´ë¸Œë¦¬ë“œ
            results = hybrid_recommend(user_input, prompts)

        if results:
            st.subheader("ğŸ” ì¶”ì²œ í”„ë¡¬í”„íŠ¸")
            for item in results:
                st.markdown(f"**{item.get('title')}**")
                st.code(item.get("prompt", ""), language="text")
                info_parts = [f"ë¶„ì•¼: `{item.get('category')}`", f"ë„êµ¬: `{item.get('tool')}`", f"ë ˆë²¨: `{item.get('level')}`"]
                if 'similarity_score' in item:
                    info_parts.append(f"ìœ ì‚¬ë„: `{item['similarity_score']:.3f}`")
                st.markdown(" / ".join(info_parts))
                st.markdown("---")
        else:
            st.warning("ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì…ë ¥ì„ ì¢€ ë” êµ¬ì²´í™”í•´ë³´ì„¸ìš”.")

# Tab 2: í”„ë¡¬í”„íŠ¸ ëª©ë¡
with tab2:
    st.subheader("ğŸ“„ ì „ì²´ í”„ë¡¬í”„íŠ¸ ëª©ë¡")
    prompts = load_prompts()
    if prompts:
        for item in prompts:
            with st.expander(f"{item.get('title')} [{item.get('category')}]"):
                st.markdown(item.get("prompt", ""))
                st.markdown(
                    f"ë ˆë²¨: `{item.get('level')}` / ë„êµ¬: `{item.get('tool')}` / í‚¤ì›Œë“œ: {', '.join(item.get('keywords', []))}"
                )
    else:
        st.info("ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. â• 'í”„ë¡¬í”„íŠ¸ ì¶”ê°€' íƒ­ì—ì„œ ìƒˆ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”.")

# Tab 3: í”„ë¡¬í”„íŠ¸ ì¶”ê°€
with tab3:
    st.subheader("â• ìƒˆ í”„ë¡¬í”„íŠ¸ ì¶”ê°€")
    with st.form("add_form"):
        title = st.text_input("í”„ë¡¬í”„íŠ¸ ì œëª©")
        prompt = st.text_area("í”„ë¡¬í”„íŠ¸ ë‚´ìš©")
        category = st.selectbox(
            "ë¶„ì•¼", ["í”„ë¡ íŠ¸ì—”ë“œ", "ë°±ì—”ë“œ", "AI/LLM", "ë°ì´í„°ë¶„ì„", "DevOps", "ê¸°ì´ˆ"]
        )
        tool = st.text_input("ë„êµ¬ ì´ë¦„ (ì˜ˆ: React, FastAPI)")
        framework = st.text_input("í”„ë ˆì„ì›Œí¬ ì´ë¦„ (ì˜ˆ: Next.js, Streamlit)")
        level = st.selectbox("ë ˆë²¨", ["ì…ë¬¸", "ì¤‘ê¸‰", "ê³ ê¸‰"])
        keywords = st.text_input("í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)")
        submitted = st.form_submit_button("ì €ì¥")
        if submitted:
            new_item = {
                "id": str(uuid4()),
                "title": title,
                "prompt": prompt,
                "category": category,
                "tool": tool,
                "framework": framework,
                "level": level,
                "keywords": [kw.strip() for kw in keywords.split(",") if kw.strip()]
            }
            prompts = load_prompts()
            prompts.append(new_item)
            save_prompts(prompts)
            st.success("í”„ë¡¬í”„íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
